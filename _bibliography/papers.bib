---
---


@INPROCEEDINGS{oh2024,
  author={Oh, Tae Il and Nam, Hong Chul and Park, Chanwoo and Cho, Hyunbo},
  booktitle={2024 International Conference on Simulation of Semiconductor Processes and Devices (SISPAD)}, 
  title={FuncAnoDe: A Function Level Anomaly Detection in Device Simulation}, 
  year={2024},
  volume={},
  number={},
  abstract={In semiconductor device simulations, the reliance on empirical compact models, such as the Berkeley Short-channel IGFET Model (BSIM) and neural compact models, introduces approximations that may significantly diverge from actual physical phenomena. Identifying and filtering out unphysical behaviors and erroneous simulation outcomes is a challenging task, traditionally requiring extensive expert involvement and incurring high costs. In response, we introduce FuncAnoDe, a novel neural operator for unsupervised functional anomaly detection in semiconductor simulation datasets. FuncAnoDe is the first to offer deep learning-based function-level anomaly detection without manual expert intervention. Its function-level encoder-decoder architecture enables applications across a diverse range of device parameters and simulations, ensuring scalability and high accuracy in identifying physically implausible parameter configurations. Our evaluations were conducted through complex capacitance-voltage (C-V) curve analysis, and FuncAnoDe demonstrated its effectiveness in anomaly detection by achieving a 100.00\% accuracy without reliance on manual labeling. FuncAnoDe provides a methodological advancement that enhances the precision, reliability, and efficiency of semiconductor design and simulation workflows.},
}

@InProceedings{pmlr-v235-nam24a,
  title = 	 {Solving Poisson Equations using Neural Walk-on-Spheres},
  author =       {Nam, Hong Chul and Berner, Julius and Anandkumar, Anima},
  booktitle = 	 {Proceedings of the 41st International Conference on Machine Learning},
  pages = 	 {37277--37292},
  year = 	 {2024},
  editor = 	 {Salakhutdinov, Ruslan and Kolter, Zico and Heller, Katherine and Weller, Adrian and Oliver, Nuria and Scarlett, Jonathan and Berkenkamp, Felix},
  volume = 	 {235},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {21--27 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://raw.githubusercontent.com/mlresearch/v235/main/assets/nam24a/nam24a.pdf},
  url = 	 {https://proceedings.mlr.press/v235/nam24a.html},
  abstract = 	 {We propose Neural Walk-on-Spheres (NWoS), a novel neural PDE solver for the efficient solution of high-dimensional Poisson equations. Leveraging stochastic representations and Walk-on-Spheres methods, we develop novel losses for neural networks based on the recursive solution of Poisson equations on spheres inside the domain. The resulting method is highly parallelizable and does not require spatial gradients for the loss. We provide a comprehensive comparison against competing methods based on PINNs, the Deep Ritz method, and (backward) stochastic differential equations. In several challenging, high-dimensional numerical examples, we demonstrate the superiority of NWoS in accuracy, speed, and computational costs. Compared to commonly used PINNs, our approach can reduce memory usage and errors by orders of magnitude. Furthermore, we apply NWoS to problems in PDE-constrained optimization and molecular dynamics to show its efficiency in practical applications.}
}
@inproceedings{nam2023npcnis,
  title={{NPC}-{NIS}: Navigating Semiconductor Process Corners with Neural Importance Sampling},
  author={Hong Chul Nam and Chanwoo Park},
  booktitle={NeurIPS 2023 Workshop on Adaptive Experimental Design and Active Learning in the Real World},
  year={2023},
  pdf={https://openreview.net/pdf?id=QIwA1zUd2t},
  url={https://openreview.net/forum?id=QIwA1zUd2t},
  abstract={Traditional corner case analysis in semiconductor circuit design typically involves the use of predetermined semiconductor process parameters, including Fast, Typical, and Slow corners for PMOS and NMOS devices, frequently yielding overly conservative designs due to the utilization of fixed, and potentially non-representative, process parameter values for circuit simulations. Identifying the worst cases of circuit FoMs within typical semiconductor process variation ranges presents a considerable challenge, especially given the complexities associated with accurately sampling rare semiconductor events. In response, we introduce NPC-NIS, a model specifically developed for estimating rare cases in semiconductor circuit analysis, leveraging a learnable importance sampling strategy. We model the distribution of process parameters that exhibit the worst FoMs within a realistic range. This adaptable framework dynamically identifies and addresses rare semiconductor cases within typical process variation ranges, enhancing our circuit design optimization capabilities under realistic conditions. Our empirical results validate the effectiveness of the Neural Importance Sampling (NIS) approach in identifying and mitigating rare semiconductor scenarios, thereby contributing to the development of more robust and reliable semiconductor circuit designs and connecting traditional semiconductor corner case analysis with realworld semiconductor applications.}
}

@INPROCEEDINGS{10319551,
  author={Park, Chanwoo and Nam, Hong Chul and Park, Jihun and Jeon, Jongwook},
  booktitle={2023 International Conference on Simulation of Semiconductor Processes and Devices (SISPAD)}, 
  title={FlowSim: An Invertible Generative Network for Efficient Statistical Analysis under Process Variations}, 
  year={2023},
  volume={},
  number={},
  pages={157-160},
  abstract={The analysis of statistical variation in circuits or devices, resulting from process, voltage, and temperature (PVT) variations, is a critical aspect of ensuring high yield and accurate high-sigma analysis in semiconductor fabrication. As the industry progresses toward nanometer technologies, process variation becomes a significant challenge, necessitating the development of effective statistical models. Traditional Monte Carlo simulations, however, struggle to scale with the increasing number of process variables, leading to an exponential growth in the required simulations. In response to this challenge, we introduce FlowSim, a novel approach that employs density estimation to accurately perform yield and high-sigma analysis with a significantly reduced number of simulations. This approach offers a unique solution to the scalability issues faced by conventional Monte Carlo simulations, providing over a 100x decrease in the number of required simulations while maintaining a prediction error below 5% across all statistical metrics of circuit performance.},
  url={https://ieeexplore.ieee.org/document/10319551},
  keywords={Analytical models;Temperature distribution;Monte Carlo methods;Circuit optimization;Scalability;Neural networks;Estimation;Statistical variation;Monte Carlo simulation;High-sigma analysis;Artificial neural network},
  doi={10.23919/SISPAD57422.2023.10319551}
}

@inproceedings{10.1145/3613424.3614276,
author = {Kanellopoulos, Konstantinos and Nam, Hong Chul and Bostanci, Nisa and Bera, Rahul and Sadrosadati, Mohammad and Kumar, Rakesh and Bartolini, Davide Basilio and Mutlu, Onur},
title = {Victima: Drastically Increasing Address Translation Reach by Leveraging Underutilized Cache Resources},
year = {2023},
isbn = {9798400703294},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613424.3614276},
doi = {10.1145/3613424.3614276},
abstract = {Address translation is a performance bottleneck in data-intensive workloads due to large datasets and irregular access patterns that lead to frequent high-latency page table walks (PTWs). PTWs can be reduced by using (i) large hardware TLBs or (ii) large software-managed TLBs. Unfortunately, both solutions have significant drawbacks: increased access latency, power and area (for hardware TLBs), and costly memory accesses, the need for large contiguous memory blocks, and complex OS modifications (for software-managed TLBs). We present Victima, a new software-transparent mechanism that drastically increases the translation reach of the processor by leveraging the underutilized resources of the cache hierarchy. The key idea of Victima is to repurpose L2 cache blocks to store clusters of TLB entries, thereby providing an additional low-latency and high-capacity component that backs up the last-level TLB and thus reduces PTWs. Victima has two main components. First, a PTW cost predictor (PTW-CP) identifies costly-to-translate addresses based on the frequency and cost of the PTWs they lead to. Leveraging the PTW-CP, Victima uses the valuable cache space only for TLB entries that correspond to costly-to-translate pages, reducing the impact on cached application data. Second, a TLB-aware cache replacement policy prioritizes keeping TLB entries in the cache hierarchy by considering (i) the translation pressure (e.g., last-level TLB miss rate) and (ii) the reuse characteristics of the TLB entries. Our evaluation results show that in native (virtualized) execution environments Victima improves average end-to-end application performance by 7.4\% (28.7\%) over the baseline four-level radix-tree-based page table design and by 6.2\% (20.1\%) over a state-of-the-art software-managed TLB, across 11 diverse data-intensive workloads. Victima delivers similar performance as a system that employs an optimistic 128K-entry L2 TLB, while avoiding the associated area and power overheads. Victima (i) is effective in both native and virtualized environments, (ii) is completely transparent to application and system software, (iii) unlike large software-managed TLBs, does not require contiguous physical allocations, (iv) is compatible with modern large page mechanisms and (iv) incurs very small area and power overheads of and , respectively, on a modern high-end CPU. The source code of Victima is freely available at https://github.com/CMU-SAFARI/Victima.},
booktitle = {Proceedings of the 56th Annual IEEE/ACM International Symposium on Microarchitecture},
pages = {1178–1195},
numpages = {18},
keywords = {Address Translation, Cache, Memory Hierarchy, Memory Systems, Microarchitecture, TLB, Virtual Memory, Virtualization},
location = {Toronto, ON, Canada},
series = {MICRO '23}
}

